{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebApps for ML in Colab",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praxis-bs/DEMD/blob/main/WebApps_for_ML_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAcxEwXbZPVb"
      },
      "source": [
        "![alt text](https://4.bp.blogspot.com/-gbL5nZDkpFQ/XScFYwoTEII/AAAAAAAAAGY/CcVb_HDLwvs2Brv5T4vSsUcz7O4r2Q79ACK4BGAYYCw/s1600/kk3-header00-beta.png)<br>\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "[Prithwis Mukerjee](http://www.linkedin.com/in/prithwis)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQPJOQXTb2y4"
      },
      "source": [
        "#Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSX3XxMLVvTR"
      },
      "source": [
        "This exercise is loosely modelled on the tutorial given in https://pythonspot.com/flask-web-app-with-python/ except that instead of working with a local machine where the TCPIP ports are easily accessible, we use Google Colab where such ports are not easily accessible. To overcome this problem we use ngrok tunnelling technology that creates a publicly accessible URL that can access TCPIP applications running on any Google Colab VM port <br>\n",
        "All files used in these exercises are availale at https://drive.google.com/drive/folders/1SzeS5AqnCNa9FTSeUHCGcJsClrGNlGVt?usp=sharing <br> <br>\n",
        "Other ways of achieving this are as follows \n",
        "\n",
        "\n",
        "*   flask-ngrok - https://pypi.org/project/flask-ngrok/\n",
        "*   pyngrok - https://pypi.org/project/pyngrok/\n",
        "<br>\n",
        "However the MOST SIMPLEST way to access a port in google colab is to follow the instructions given in <br>\n",
        " https://stackoverflow.com/questions/59741453/is-there-a-general-way-to-run-web-applications-on-google-colab <br>\n",
        "\n",
        "see https://colab.research.google.com/drive/1XIz5OE3CqvlqjyYPQxrO-zhlVa8ZhMA0?usp=sharing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOULZNaBZ9Hi"
      },
      "source": [
        "#ngrok configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsGoGUdaWVc1"
      },
      "source": [
        "ngrok needs an authentication token. this can be easily hardcoded into this notebook ( as shown in one of the cells below) To avoid hardcoding -- and revealing the same in a public notebook -- the token is stored in Google Drive and accessed by mounting the G-Drive on the Colab VM <br>\n",
        "See \n",
        "\n",
        "\n",
        "1.   https://ngrok.com/ - login \n",
        "2.   https://dashboard.ngrok.com/get-started/setup - get your authtoken\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3SEBQ8haAyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068364ec-b346-4263-998b-2f3de5ff3349"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cPJEPTlZHWZ"
      },
      "source": [
        "#!ls /content/drive/'My Drive'/Praxis/WebCredentials\n",
        "!cp /content/drive/'My Drive'/Praxis/WebCredentials/ngrokToken.py ."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9SSlpYOajyi"
      },
      "source": [
        "# credential file for Prithwis Mukerjee\n",
        "# this file needs to be uploaded into the VM\n",
        "\n",
        "from ngrokToken import ngrokToken\n",
        "\n",
        "#for the sake of privacy\n",
        "#the following credentials need to be stored in a text file called ngrokToken.py\n",
        "#in the format given below\n",
        "#in the Colab VM\n",
        "\n",
        "#otherwise, the values can be directly placed here\n",
        "\n",
        "#ngrokToken = '1kUOcwwwwwwwwRHsdVJRGMeTdddddddddddYbPZhxod'   # uncomment this line and place your own credentials here\n",
        "#token is available at https://dashboard.ngrok.com/get-started/setup\n",
        "\n",
        "\n",
        "#print(ngrokToken)\n",
        "ngrokTokenCmd = 'ngrok authtoken '+ngrokToken"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ8PfUXqa8lY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8496e434-9706-4064-c52c-3e697f85041e"
      },
      "source": [
        "#https://ngrok.com/download\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-24 15:30:32--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.45.123.219, 44.194.107.75, 44.193.92.248, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.45.123.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  26.9MB/s    in 0.5s    \n",
            "\n",
            "2021-08-24 15:30:32 (26.9 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFfNwKkjbYCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa87f2c-4b74-432f-b2e0-446cd4e11aa9"
      },
      "source": [
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QsdOd_kcReo"
      },
      "source": [
        "#!./ngrok authtoken xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
        "get_ipython().system_raw(ngrokTokenCmd)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQc5h1i_gfwz"
      },
      "source": [
        "!apt-get install jq > null"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZR5rhPujugQ"
      },
      "source": [
        "#WebApp Linear Regression - Wine Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgDAZRTSWyK2"
      },
      "source": [
        "Web apps need additionl files for HTML, images, data etc that need to be stored on appropriate directories. These files can either be created in a local machine and uploaded into the appropriate directory, or loaded from GDrive or Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOOorm-amzNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd052e2-523b-4dac-beaa-f6103fb4045e"
      },
      "source": [
        "!mkdir static\n",
        "!mkdir templates\n",
        "!mkdir datafiles"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘static’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L7nQRLd3m_9"
      },
      "source": [
        "!wget https://github.com/Praxis-bs/DEMD/raw/main/static/kkpraxis.png      # image file\n",
        "\n",
        "!wget https://raw.githubusercontent.com/Praxis-bs/DEMD/main/templates/LR_home.html    # home\n",
        "!wget https://raw.githubusercontent.com/Praxis-bs/DEMD/main/templates/LR_predict1.html  # output\n",
        "\n",
        "!wget https://github.com/Praxis-bs/DEMD/raw/main/datafiles/lrw-model.pkl # model file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEUfWPF-y9e7",
        "outputId": "3525a4f4-8afb-4a59-f047-af7a86e07e16"
      },
      "source": [
        "!mv kkpraxis.png static\n",
        "!mv *.html templates/\n",
        "!mv *.pkl datafiles/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-24 15:34:36--  https://github.com/Praxis-bs/DEMD/raw/main/static/kkpraxis.png\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Praxis-bs/DEMD/main/static/kkpraxis.png [following]\n",
            "--2021-08-24 15:34:36--  https://raw.githubusercontent.com/Praxis-bs/DEMD/main/static/kkpraxis.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33605 (33K) [image/png]\n",
            "Saving to: ‘kkpraxis.png’\n",
            "\n",
            "kkpraxis.png        100%[===================>]  32.82K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-08-24 15:34:37 (15.6 MB/s) - ‘kkpraxis.png’ saved [33605/33605]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jGcHAixivJn"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 5010 &')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyj-bdsxizAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa5cdba-9b08-4d8b-8594-0c017556d3fe"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | jq .tunnels[0].public_url\n",
        "!curl -s http://localhost:4040/api/tunnels | jq .tunnels[0].config.addr"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0;32m\"https://437f-34-73-118-25.ngrok.io\"\u001b[0m\n",
            "\u001b[0;32m\"http://localhost:5010\"\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqNL8PJwidHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852951e6-d7e1-498c-b194-ee4de2e89507"
      },
      "source": [
        "# https://pythonspot.com/flask-web-app-with-python/\n",
        "# COLAB where model is trained, tested\n",
        "# Train : https://colab.research.google.com/drive/1G3VUKVUspcoDnLRobuUfsGTswpCMkU8W\n",
        "# Predict : https://colab.research.google.com/drive/1gF9DI4NT5tH_9lcbVth-kVEZ9sO7wnhU\n",
        "# docker build -t calcutta/de-applrw02 .\n",
        "# docker run --rm --name praxislrw -p 5002:5000 calcutta/de-applrw02\n",
        "\n",
        "from sys import argv\n",
        "from flask import Flask, flash, redirect, render_template, request, session, abort\n",
        "\n",
        "import pickle\n",
        "from sklearn import linear_model\n",
        "\n",
        "app = Flask(__name__)\n",
        "scriptName = argv[0]\n",
        "\n",
        "@app.route(\"/\")\n",
        "def hello():\n",
        "    retString = 'ML LRW now running ... '+scriptName\n",
        "    return retString\n",
        "\n",
        "@app.route('/home')\n",
        "def home():\n",
        "    return render_template('LR_home.html')\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/predict1/<featureString>')\n",
        "def multidata(featureString):\n",
        "    str1 = featureString\n",
        "    feature_list = featureString.split(\",\")\n",
        "    feature_array = list(map(lambda x : float(x), feature_list))\n",
        "\n",
        "    model = pickle.load(open(\"datafiles/lrw-model.pkl\",\"rb\"))\n",
        "\n",
        "    #our model rates the wine based on the input array\n",
        "    prediction = model.predict([feature_array]).tolist()\n",
        "\n",
        "    return render_template('LR_predict1.html',**locals())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"localhost\", port=5010)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://localhost:5010/ (Press CTRL+C to quit)\n",
            "127.0.0.1 - - [24/Aug/2021 15:52:08] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [24/Aug/2021 15:52:09] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [24/Aug/2021 15:52:15] \"\u001b[37mGET /home HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [24/Aug/2021 15:52:15] \"\u001b[37mGET /static/kkpraxis.png HTTP/1.1\u001b[0m\" 200 -\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 0.18.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "127.0.0.1 - - [24/Aug/2021 15:52:38] \"\u001b[37mGET /predict1/7.4,0.66,0,1.8,0.075,13,40,0.9978,3.51,0.56,9.4 HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mEJhPGxyLmK"
      },
      "source": [
        "#ML - Image Classification <br>\n",
        "https://blog.hyperiondev.com/index.php/2018/02/01/deploy-machine-learning-model-flask-api/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khd-GqUyyfWn"
      },
      "source": [
        "#!cp /content/drive/'My Drive'/Praxis/'Course - DevOps'/DevOps/ml/appimclass02/datafiles/*.pkl datafiles\n",
        "#https://drive.google.com/file/d/1o6Z02Q-KATgEXSGbQ8XK_H62Dv7BW4eW/view?usp=sharing\n",
        "!gdown https://drive.google.com/uc?id=1o6Z02Q-KATgEXSGbQ8XK_H62Dv7BW4eW\n",
        "\n",
        "#!cp /content/drive/'My Drive'/Praxis/'Course - DevOps'/DevOps/ml/appimclass02/templates/index.html templates \n",
        "#https://drive.google.com/file/d/1pNiq27_abII3mj8PFui1dn1mrKCLlPKd/view?usp=sharing\n",
        "!gdown https://drive.google.com/uc?id=1pNiq27_abII3mj8PFui1dn1mrKCLlPKd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJcpzR4_YdkE"
      },
      "source": [
        "!mv *.pkl datafiles/\n",
        "!mv index.html templates/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdBdWwMLzQR7"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 5010 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2Lgpc77zU6g"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | jq .tunnels[0].public_url\n",
        "!curl -s http://localhost:4040/api/tunnels | jq .tunnels[0].config.addr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT6w6oHjyOxz"
      },
      "source": [
        "# https://pythonspot.com/flask-web-app-with-python/\n",
        "# https://blog.hyperiondev.com/index.php/2018/02/01/deploy-machine-learning-model-flask-api/\n",
        "# COLAB for train, test, model build https://colab.research.google.com/drive/1JuTezUiqM0Cj_m-FmmeBzw_88xZlYeK-\n",
        "# docker build -t calcutta/de-appimc02 .\n",
        "# docker run --rm --name praxisimc -p 5000:5000 calcutta/de-appimc02\n",
        "\n",
        "# test images available at https://github.com/elliebirbeck/model-deployment-flask/tree/master/test-imgs\n",
        "\n",
        "\n",
        "from sys import argv\n",
        "from flask import Flask, flash, redirect, render_template, request, session, abort, url_for\n",
        "\n",
        "import pickle\n",
        "from sklearn import linear_model\n",
        "#from sklearn.externals import joblib\n",
        "import joblib\n",
        "from sklearn.ensemble import *\n",
        "\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "scriptName = argv[0]\n",
        "\n",
        "@app.route(\"/\")\n",
        "def hello():\n",
        "    retString = 'now running ... '+scriptName\n",
        "    return retString\n",
        "\n",
        "@app.route('/home')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def make_prediction():\n",
        "    if request.method=='POST':\n",
        "        file = request.files['image']\n",
        "        if not file: \n",
        "            return render_template('index.html', label=\"No file\")\n",
        "        #f = 'datafiles/'+str(file.filename)\n",
        "        #file.save(f)\n",
        "        \n",
        "        img = imageio.imread(file)\n",
        "        img = img[:,:,:3]\n",
        "        img = img.reshape(1, -1)\n",
        "        prediction = model.predict(img)\n",
        "        label = str(np.squeeze(prediction))\n",
        "        if label=='10': \n",
        "            label='0'\n",
        "        return render_template('index.html', label=label, file=file)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = joblib.load('datafiles/imClass-model-18032020.pkl')\n",
        "    app.run(host=\"localhost\", port=5010)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNcZp8DBpU8z"
      },
      "source": [
        "#ML Tensorflow + Keras deprecated <br>\n",
        "too many changes in versions etc .. <br>\n",
        "this app does not work anymore "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYy7J19EpmZF"
      },
      "source": [
        "!cp /content/drive/'My Drive'/Praxis/'Course - DevOps'/DevOps/ml/apptfk2/games-17032020.h5 datafiles\n",
        "!cp /content/drive/'My Drive'/Praxis/'Course - DevOps'/DevOps/ml/apptfk2/templates/home.html templates/home_tfk.html\n",
        "!cp /content/drive/'My Drive'/Praxis/'Course - DevOps'/DevOps/ml/apptfk2/templates/predict2.html templates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDizmDrLrJDm"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 5010 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXaAXrMprM3t"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | jq .tunnels[0].public_url\n",
        "!curl -s http://localhost:4040/api/tunnels | jq .tunnels[0].config.addr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AV879ZqpZpC"
      },
      "source": [
        "# tutorial from https://www.houseofbots.com/news-detail/4528-1-how-to-deploy-keras-deep-learning-models-with-flask\n",
        "# model is built in colab https://colab.research.google.com/drive/1sn7BS1uqPdmiAb2Ez1Q0EcpwwNeioCY0\n",
        "# docker build -t calcutta/de-apptfk02 .\n",
        "# docker run --rm --name praxis007 -p 8888:5000 calcutta/de-apptfk02\n",
        "# jsonify error see https://stackoverflow.com/questions/60131900/weird-is-xhr-error-when-deploying-flask-app-to-heroku\n",
        "\n",
        "from sys import argv\n",
        "\n",
        "# Load libraries\n",
        "\n",
        "import flask\n",
        "from flask import Flask, flash, redirect, render_template, request, session, abort\n",
        "import pandas as pd\n",
        "#import tensorflow as tf\n",
        "#import keras\n",
        "#from keras.models import load_model\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "\n",
        "# instantiate flask \n",
        "app = flask.Flask(__name__)\n",
        "#app = Flask(__name__)\n",
        "scriptName = argv[0]\n",
        "\n",
        "# we need to redefine our metric function in order \n",
        "# to use it when loading the model \n",
        "def auc(y_true, y_pred):\n",
        "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
        "    keras.backend.get_session().run(tf.local_variables_initializer())\n",
        "    return auc\n",
        "# load the model, and pass in the custom metric function\n",
        "global graph\n",
        "#graph = tf.get_default_graph()\n",
        "graph = tf.compat.v1.get_default_graph()\n",
        "#model = load_model('./games.h5', custom_objects={'auc': auc})\n",
        "model = load_model('datafiles/games-17032020.h5', custom_objects={'auc': auc})\n",
        "model.run_eagerly = True\n",
        "\n",
        "\n",
        "@app.route(\"/\")\n",
        "def hello():\n",
        "    retString = 'APPTFK2 running '+scriptName+' go to /home for more information'\n",
        "    return retString\n",
        "\n",
        "@app.route('/home')\n",
        "def home():\n",
        "    return render_template('home_tfk.html')\n",
        "\n",
        "# define a predict function as an endpoint \n",
        "@app.route(\"/predict\", methods=[\"GET\",\"POST\"])\n",
        "def predict():\n",
        "    data = {\"success\": False}\n",
        "    params = flask.request.json\n",
        "    \n",
        "    if (params == None):\n",
        "       params = flask.request.args\n",
        "       \n",
        "    #params = {'g1':1,'g2':0,'g3':0,'g4':0,'g5':0,'g6':0,'g7':0,'g8':0,'g9':0,'g10':0}\n",
        "    # if parameters are found, return a prediction\n",
        "    if (params != None):\n",
        "        x=pd.DataFrame.from_dict(params, orient='index').transpose()\n",
        "        with graph.as_default():\n",
        "            data[\"prediction\"] = str(model.predict(x)[0][0])\n",
        "            data[\"success\"] = True\n",
        "    # return a response in json format \n",
        "    return flask.jsonify(data)  \n",
        "\n",
        "# define a predict function as an endpoint \n",
        "@app.route(\"/predict2\", methods=[\"GET\",\"POST\"])\n",
        "def predict2():\n",
        "    data = {\"success\": False}\n",
        "    params = flask.request.json\n",
        "    \n",
        "    if (params == None):\n",
        "       params = flask.request.args\n",
        "       \n",
        "    #params = {'g1':1,'g2':0,'g3':0,'g4':0,'g5':0,'g6':0,'g7':0,'g8':0,'g9':0,'g10':0}\n",
        "    # if parameters are found, return a prediction\n",
        "    if (params != None):\n",
        "        x=pd.DataFrame.from_dict(params, orient='index').transpose()\n",
        "        with graph.as_default():\n",
        "            prediction = str(model.predict(x)[0][0])\n",
        "            status = True\n",
        "    return render_template('predict2.html',**locals())\n",
        "      \n",
        "# start the flask app, allow remote connections \n",
        "app.run(host=\"localhost\", port=5010)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3qK5YHXZWqT"
      },
      "source": [
        "#Chronobooks <br>\n",
        "![alt text](https://1.bp.blogspot.com/-lTiYBkU2qbU/X1er__fvnkI/AAAAAAAAjtE/GhDR3OEGJr4NG43fZPodrQD5kbxtnKebgCLcBGAsYHQ/s600/Footer2020-600x200.png)<hr>\n",
        "Chronotantra and Chronoyantra are two science fiction novels that explore the collapse of human civilisation on Earth and then its rebirth and reincarnation both on Earth as well as on the distant worlds of Mars, Titan and Enceladus. But is it the human civilisation that is being reborn? Or is it some other sentience that is revealing itself. \n",
        "If you have an interest in AI and found this material useful, you may consider buying these novels, in paperback or kindle, from [http://bit.ly/chronobooks](http://bit.ly/chronobooks)"
      ]
    }
  ]
}